{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "896a5171-e447-4107-96ea-e86c5c95ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ddfc5cc-5952-43a3-8066-de7bbcc0423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://segmentation-models-pytorch.readthedocs.io/en/latest/models.html#unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c92bd6a3-eaeb-4022-b668-4a65cb98f275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to C:\\Users\\milio/.cache\\torch\\hub\\checkpoints\\resnet34-333f7ec4.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 83.3M/83.3M [00:07<00:00, 11.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=3,                      # model output channels (number of classes in your dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae692723-751c-44a0-a2d3-1889fd0aef4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'resnext50_32x4d', 'resnext101_32x4d', 'resnext101_32x8d', 'resnext101_32x16d', 'resnext101_32x32d', 'resnext101_32x48d', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn107', 'dpn131', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'inceptionresnetv2', 'inceptionv4', 'efficientnet-b0', 'efficientnet-b1', 'efficientnet-b2', 'efficientnet-b3', 'efficientnet-b4', 'efficientnet-b5', 'efficientnet-b6', 'efficientnet-b7', 'mobilenet_v2', 'xception', 'timm-efficientnet-b0', 'timm-efficientnet-b1', 'timm-efficientnet-b2', 'timm-efficientnet-b3', 'timm-efficientnet-b4', 'timm-efficientnet-b5', 'timm-efficientnet-b6', 'timm-efficientnet-b7', 'timm-efficientnet-b8', 'timm-efficientnet-l2', 'timm-tf_efficientnet_lite0', 'timm-tf_efficientnet_lite1', 'timm-tf_efficientnet_lite2', 'timm-tf_efficientnet_lite3', 'timm-tf_efficientnet_lite4', 'timm-resnest14d', 'timm-resnest26d', 'timm-resnest50d', 'timm-resnest101e', 'timm-resnest200e', 'timm-resnest269e', 'timm-resnest50d_4s2x40d', 'timm-resnest50d_1s4x24d', 'timm-res2net50_26w_4s', 'timm-res2net101_26w_4s', 'timm-res2net50_26w_6s', 'timm-res2net50_26w_8s', 'timm-res2net50_48w_2s', 'timm-res2net50_14w_8s', 'timm-res2next50', 'timm-regnetx_002', 'timm-regnetx_004', 'timm-regnetx_006', 'timm-regnetx_008', 'timm-regnetx_016', 'timm-regnetx_032', 'timm-regnetx_040', 'timm-regnetx_064', 'timm-regnetx_080', 'timm-regnetx_120', 'timm-regnetx_160', 'timm-regnetx_320', 'timm-regnety_002', 'timm-regnety_004', 'timm-regnety_006', 'timm-regnety_008', 'timm-regnety_016', 'timm-regnety_032', 'timm-regnety_040', 'timm-regnety_064', 'timm-regnety_080', 'timm-regnety_120', 'timm-regnety_160', 'timm-regnety_320', 'timm-skresnet18', 'timm-skresnet34', 'timm-skresnext50_32x4d']\n"
     ]
    }
   ],
   "source": [
    "from segmentation_models_pytorch.encoders import get_encoder_names\n",
    "\n",
    "# List all available encoders\n",
    "encoders = get_encoder_names()\n",
    "print(encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dafbf1-48fc-441e-891f-cd1b94758485",
   "metadata": {},
   "source": [
    "1. Install Required Libraries\n",
    "2. Prepare Your Data\n",
    "3. Define Dataset and DataLoader\n",
    "4. Load the Pretrained Model    \n",
    "5. Define Loss Function and Optimizer\n",
    "6. Training Loop\n",
    "7. Evaluate the Model\n",
    "8. Save the Trained Model\n",
    "\n",
    "Key considerations:\n",
    "1. Data Augmentation:\n",
    "Apply augmentations (e.g., flips, rotations, cropping) to increase dataset variability and improve generalization.\n",
    "Use libraries like albumentations for this.\n",
    "\n",
    "3. Fine-Tuning:\n",
    "Start with a low learning rate to fine-tune the pretrained encoder without overwriting the learned features.\n",
    "\n",
    "\n",
    "3. Evaluation Metrics:\n",
    "Use Dice Score, Intersection over Union (IoU), or F1 Score to evaluate segmentation performance.\n",
    "Let me know if you need clarification or further details!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864706e-fcc9-493f-97b2-292b328ebaeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSc Thesis",
   "language": "python",
   "name": "msc_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
