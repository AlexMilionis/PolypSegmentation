# TODO:
    #   General
        #   write down all processes before continuing further
        #   check MONAI
        #   training on notebooks?
        #   gpu sources, mail me slurm
        #   EDA
    #   Preprocessing
        #   data split: train(C1-C4), validation C5, test C6 ?
    #   Models
        ## UNet (smp)
            # lr: 0.001, 0.0001
            # batch size: 16, 32
            # loss function: bcewithlogitsloss, diceloss+bcewithlogitsloss
            # encoder backbone: resnet18 vs resnet50
            # write model description in LATEX
        ## model 2
        ## model 3 (huggingface)
        #   check https://github.com/milesial/Pytorch-UNet
        #   implement UNet
        #   study UNet (with resnet backbone)
        #   write report
        #   check segmentation models from huggingface
    #   Training
        #   learning rate
            # 0.01 -> 0.001 or 0.0001
            # scheduler like ReduceLROnPlateau
        # loss function
            # smp.losses.DiceLoss(mode='binary') + nn.BCEWithLogitsLoss()
            # class imbalance: nn.BCEWithLogitsLoss(pos_weight=pos_weight)
        # batch size
        # train for more epochs 20-50 + use early stopping
    #   Experiments
        #   plots for train error, val error, and metrics -> save to results>visualizations
        #   experiment logs
    # Create app!


    # 04/03 -> run the different experiments, write model architecture in latex
