# TODO:
    #   General
        #   write down all processes before continuing further
        #   check MONAI
        #   training on notebooks?
        #   gpu sources, mail me slurm
        #   EDA
    #   Preprocessing
        #   data split: train(C1-C4), validation C5, test C6 ?
        #   cross validation ?
        #   dataset both single frames and sequence frames
    #   Models
        #   implement UNet
        #   study UNet (with resnet backbone)
        #   write report
        #   check segmentation models from huggingface
    #   Training
        #   Create run_unet.py
        #   Create unet_config.yaml
        #   create train.py
        #   Create hyperparameter_search.py
        #   find criterion for training
        #   make epochs faster
        #   last epoch is always slower, fix
        #   make transformations more efficient, for faster training ?
        #   Implement log file for training
        #   plots for train error, val error, and metrics -> save to results>visualizations
        #   experiment logs -
        #   cross validation?
        #   save post train visualizations in results>exp
        #   plots on test set: image, mask, predicted mask -> save to results>visualizations
        #   plots to include title the image path
        #   save test metrics to a file
    #   Experiments
        #   learn how to create .yaml configuration files
        #   create train one epoch and separate train experiment files
        #   all parameters must be taken from confugration file
# TODO: Questions:
    #   Να έχω σταθερό μέγεθος για όλες τις εικόνες? εναλλακτικά (custom collate function για μεταβλητού μήκος εικόνες)
    #   Δουλεύω μονο με single frames ή με single+sequence? Aν both, χρειάζεται να διατηρηθεί το ordering των sequence frames?
